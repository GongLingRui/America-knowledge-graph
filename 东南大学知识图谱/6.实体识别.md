# 东南大学知识抽取-命名实体识别文档总结（含注意点、易错点）
这份文档是东南大学KGCODE实验室汪鹏老师2025年3月28日的分享内容，核心围绕**知识抽取中的命名实体识别（NER）**展开，系统讲解了NER的基本概念、七大技术方法体系，还展示了模型性能对比、实际应用案例、自研优化测试结果及领域最新进展，是一份覆盖NER基础理论到前沿实践的专业资料。

## 一、核心基础内容
### 1. 命名实体识别的核心定位与价值
自然语言理解是人工智能的核心方向，多位领域大咖（比尔盖茨、Geoff Hinton、Yann Lecun等）均指出自然语言处理/理解是AI的重要发展方向，而命名实体识别是自然语言理解的关键任务。

### 2. NER的任务目标
识别文本中**三大类命名实体**：实体类（人名、组织/机构、地理位置）、时间类（时间、日期）、数字类（货币、百分比），并通过序列标注明确实体边界与类型。

### 3. 核心序列标注体系
主流标注体系包括IO、BIO、BIOES、BMEWO，以“特朗普”“白宫”为例，不同体系对实体首字符、中间字符、尾字符标注规则不同（如BIO中首字符标B-类型，后续标I-类型；BIOES中尾字符标E-类型），是NER的基础标注规范。

## 二、七大技术方法体系详解
文档按技术发展脉络，依次讲解了NER的七大方法，涵盖传统规则、机器学习、深度学习，再到半监督、迁移学习、预训练模型，各方法的核心原理、流程、模型及性能均有明确说明。
### 1. 基于规则和词典的方法
- **核心流程**：预处理（分词+词性标注）→构建词典→识别实体边界（词典匹配、拼写规则等）→实体分类（分类规则/词典）。
- **词典的作用**：辅助分词、匹配实体、实体分类；
- **词典构建方法**：统计分析（词频、TF-IDF/TextRank）+人工筛选，可复用现有语义词库（CSC、hownet、Chinese Open Wordnet），也可从词性标注、依存句法分析中抽取领域术语。
- **性能特点**：依赖词典和规则，领域适配性强，但泛化能力弱，规则维护成本高。

### 2. 基于机器学习的方法
- **主流模型**：隐马尔科夫模型（HMM）、最大熵马尔科夫模型（MEMM）、条件随机场（CRF）、支持向量机（SVM）；
- **核心差异**：HMM是**有向图+生成模型**，有特征分布独立假设；CRF是**无向图+判别式模型**，无独立假设，是该类方法中性能较优的模型。

### 3. 基于深度学习的方法
是NER的主流技术，核心为**深度学习模型+CRF**的组合，利用深度学习提取特征，CRF处理序列标注的上下文依赖，主流模型及性能如下：
1. **NN/CNN+CRF**（Collobert et al.2011）：分窗口法和句子法，在CoNLL-2003英文测试集上F1达89.59%，优于传统机器学习模型；
2. **Bi-LSTM+CRF**（Lample et al.2016）：支持词级别/字符级别嵌入，F1达90.94%，是深度学习基础经典模型；
3. **Bi-LSTM-CNN-CRF**（Ma and Hovy.2016）：融合CNN提取字符特征、Bi-LSTM提取序列特征，F1达91.21%，为该类组合模型的性能高点。

### 4. 基于半监督学习的方法
以**TagLM模型**（Peters et al.2017）为核心，解决标注数据不足的问题：
- **核心流程**：用无标注语料预训练词嵌入和语言模型→获取词嵌入+LM嵌入→混合输入序列标注模型训练；
- **模型结构**：融合预训练双向LM、Char CNN/RNN、CRF；
- **性能**：在CoNLL-2003上F1达91.93±0.19%，优于此前的深度学习模型。

### 5. 基于迁移学习的方法
- **核心定义**：利用已有知识解决新问题，核心是找到新/原问题的相似性，与传统机器学习的核心差异见下表：
  | 比较项目 | 传统机器学习 | 迁移学习 |
  |----------|--------------|----------|
  | 数据分布 | 训练/测试数据分布相同 | 训练/测试数据分布不同 |
  | 数据标注 | 需足够标注数据 | 无需足够标注数据 |
  | 模型     | 各任务单独建模 | 模型可跨任务迁移 |
- **三种迁移模式**：跨域、跨应用、跨语言，对应三种模型（T-A/T-B/T-C），适配不同迁移场景；
- **性能特点**：跨域迁移提升最显著（如PTB→Genia/0.001，T-A模型提升9.36%），跨语言迁移提升相对有限（如CoNLL03→Spanish/0.01，仅提升0.59%）。

### 6. 基于预训练的方法
以**BERT模型**（Devlin et al.2018）为核心，基于Transformer-Encoder架构：
- **核心预训练任务**：遮挡语言模型（MLM，随机mask15%词汇并预测，80%真mask、10%随机替换、10%不变）+下一个句子预测（NSP，二分类判断句子对是否连续）；
- **性能**：BERT-LARGE在CoNLL-2003上测试集F1达92.8%，显著优于此前的ELMo+BiLSTM+CRF模型。

### 7. 补充：NER最新进展（CoNLL-2003英文测试集）
目前最优模型为**ACE + document-context（Wang et al., 2021）**，F1达94.6%；此外LUKE、CL-KL、XLNet-GCN等模型F1均超93.8%，预训练模型结合外部上下文、图神经网络成为NER的发展趋势。

## 三、实际应用与自研优化测试
### 1. 应用示例
以刑事判决书为场景，成功识别出**人名（PER）、日期（DATE）、地理位置（LOC）**等实体，验证了NER在法律文本处理中的实际价值。

### 2. 东大自研KnowledgeGraph模型优化测试（V1.1对比V1.0）
**核心提升点**：姓名（NAME）各类型识别正确率大幅提升（复姓姓名从70.63%升至91.95%）、地址（ADOR）识别正确率显著提升（籍贯地址从80.59%升至97.14%）、新增7种非强规则账号识别（QQ群、微信群、抖音等）、强规则账号（Tel/mail/idcard等）保持100%识别率；
**核心下降点**：机构（COMPANY）识别正确率下降（全称从96.22%降至90.67%，简称从55.14%降至43.26%）。

## 四、关键注意点
1. **序列标注体系选择**：不同标注体系适配不同模型，BIOES相比BIO能更清晰区分实体首尾，减少标注歧义，是深度学习模型中更常用的标注方式；
2. **方法选型依据**：小样本/领域性强的场景适合**规则+词典法**；有一定标注数据适合**CRF（机器学习）**或**Bi-LSTM+CRF（深度学习）**；标注数据极少适合**半监督（TagLM）**或**迁移学习**；通用场景追求高性能优先**预训练模型（BERT）**及前沿融合模型；
3. **特征提取的重要性**：深度学习中，字符级别特征（CNN提取）+词级别特征（Bi-LSTM提取）的融合，能显著提升NER性能，是深度学习模型的核心优化方向；
4. **预训练模型的细节**：BERT的MLM并非简单mask，而是结合“真mask+随机替换+不处理”，目的是提升模型的泛化能力，避免模型过度依赖mask标签；
5. **迁移学习的场景适配**：T-A适配可标签映射的跨域迁移，T-B适配标签集不同的跨域/跨应用迁移，T-C适配跨语言迁移，需根据实际场景选择模型；
6. **模型性能评估**：NER的核心评估指标是**基于实体跨度的F1值**（而非单字符准确率），需关注实体边界的正确识别。

## 五、常见易错点
1. **混淆生成模型与判别式模型**：HMM是生成模型，建模联合概率，有特征独立假设；CRF是判别式模型，建模条件概率，无独立假设，后者更适合NER的序列标注任务，易因概念混淆选错基础模型；
2. **忽略词典/规则的基础作用**：深度学习模型虽性能优，但在领域NER中，结合领域词典能显著提升性能，易陷入“唯深度学习论”，忽略传统方法的适配性；
3. **序列标注的边界错误**：标注时易将实体首字符标为I-类型（如将“特”标为I-PER而非B-PER），导致模型无法正确识别实体边界，是标注阶段的高频错误；
4. **误判BERT的预训练任务**：将NSP视为BERT的核心任务，实际MLM是核心，NSP后续部分研究中被证明并非必要，甚至可能引入噪声；
5. **迁移学习的误区**：认为迁移学习一定能提升性能，实际跨语言/跨领域差异过大时，迁移学习提升有限甚至负向迁移（如CoNLL03→Spanish仅提升0.59%）；
6. **性能评估的单一化**：仅关注F1值，忽略实体类型的细分性能（如东大模型中姓名提升但机构下降），实际应用中需关注核心实体类型的识别效果；
7. **混淆字符嵌入与词嵌入的作用**：字符嵌入解决生僻词/未登录词的特征提取问题，词嵌入解决通用词汇的语义表示，易忽略字符嵌入对低资源/领域NER的重要性；
8. **词典构建的误区**：仅通过统计词频构建词典，未进行人工筛选和领域术语提取，导致词典噪声大，反而降低实体识别的准确率。
