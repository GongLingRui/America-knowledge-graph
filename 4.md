【时间】 00:00–01:38  
【主题】课程引言与讲师介绍

【核心知识点】
• 本周课程聚焦：知识图谱（Knowledge Graph）数据模型（Data Models）。
• 上节课回顾：介绍了属性图（Property Graph）和RDF（Resource Description Framework）数据模型。
• 本课两位专家：Dr. Petra Selmer（Neo4j，参与Cypher开发和图查询语言标准化）与Prof. Özsu（滑铁卢大学教授，分布式数据库系统专家）。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 两位讲者各有约30分钟的技术概述，最后有约20分钟深度问答时间。

【其他细节 / 补充说明】
• Prof. Özsu获得过多项专业协会（ACM, IEEE）认可及奖项（Lifetime Achievement Award, Test of Time Award）。

---

【时间】 01:47–04:01  
【主题】属性图（Property Graph）数据模型核心构成

【核心知识点】
• 属性图数据模型由三个核心构件（Constructs）组成。
• 构件1：节点（Node），又称顶点（Vertex）。
• 节点属性1：可以有零个或多个标签（Labels）。
• 节点属性2：可以有零个或多个属性（Properties）。
• 属性（Property）：是名称-值对（Name-Value Pairs）。
• 关键特性：拥有完全相同标签集合的两个节点，其属性可以完全不同，这体现了图数据的异构性（Heterogeneous Nature）。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 节点是模型中的实体，但单独的节点用处不大，需要边来构建结构和语义。

---

【时间】 04:06–05:44  
【主题】关系（边）的构成与属性

【核心知识点】
• 构件2：关系（Relationship），又称边（Edge）。
• 边的核心作用：为图添加结构，为节点提供语义上下文（Semantic Context）。
• 边的必须属性1：有且仅有一个类型（Type），类似于节点的标签，但一个边只能有一个类型。
• 边的必须属性2：具有方向性，有起始节点（Outgoing Node）和终止节点（Incoming Node）。
• 边的可选属性：可以有零个或多个属性（Properties）。
• 特殊边：自边（Self Edge），即起始节点和终止节点是同一个节点。
• 属性的通用规则：适用于节点和边。属性名通常是字符串（String），属性值可以是整数（Integer）、小数（Decimal）、字符串（String）或列表（List）等类型。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 边必须有起始和终止节点。
⚠️ 边可以有零个属性，这在某些场景下是存在的。

---

【时间】 06:18–09:11  
【主题】Cypher查询语言的起源、特点与适用场景

【核心知识点】
• Cypher由Neo4j于2010年开发。
• 2015年，Cypher开源，形成了开放Cypher项目（Open Cypher Project），允许任何实现者（厂商、研究者）使用。
• Cypher继承了SQL和SparQL的语言特性与能力。
• Cypher的组成部分：包括声明式（Declarative）的读取（DCL）、数据操作（DML）以及约束（Constraints）和索引（Indexes）管理。
• Cypher的独特卖点（Unique Selling Points）：易于表达图模式（Graph Patterns）、支持递归查询（Recursive Queries）、支持可变长度关系链（Variable Length Relationship Chains）、支持返回路径（Paths）。
• 使用属性图数据模型（而非关系数据库）的四大场景：1. 理解实体间关系（尤其是关系种类繁多时）；2. 处理大量同类型实体自引用（Self-referencing）；3. 探索可变或未知深度（Varying or Unknown Depth）的关系；4. 发现数据中的不同路径或路由。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 本讲座重点将放在Cypher的只读（Read-Only）部分。

---

【时间】 09:17–10:34  
【主题】Cypher的核心：模式（Pattern）与MATCH子句

【核心知识点】
• Cypher的基础核心是模式（Pattern）概念。
• 模式的设计灵感：来源于ASCII艺术（ASCII Art），圆括号`()`表示节点，箭头`-->`表示边。
• 模式的应用范围：不仅是读取（MATCH子句）的核心，也广泛用于更新（Updates）、数据定义语言（DDL）语句中，是Cypher的DNA。
• 只读查询的核心结构：MATCH子句 + 模式（Pattern） + RETURN（投影）子句。
• MATCH子句：用于指定要匹配的模式。
• RETURN子句：用于投影（Projection）查询结果。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 图模式匹配（Graph Pattern Matching）是Cypher的一等公民（First-class Citizen）。

【时间】 10:47–11:34  
【主题】Cypher基础模式匹配示例解析

【核心知识点】
• 模式匹配流程：从左到右解释模式 `(:Person {name: 'Dan'})-->(:Loves)-->()`。
• 步骤1：匹配一个具有 `Person` 标签且 `name` 属性值为 `'Dan'` 的节点。
• 步骤2：查找从该节点发出的、类型为 `Loves` 的关系（边）。
• 步骤3：检查这些 `Loves` 边的另一端节点，该节点在模式中没有指定标签或属性谓词。
• 步骤4：通过 `RETURN` 语句返回另一端节点的变量。

【重要例子 / 实验】
1. 基础路径匹配：查找 `name` 为 `'Dan'` 的 `Person` 节点所爱的所有目标节点。
2. 模式构成：节点用圆括号 `()` 表示，关系用箭头 `-->` 表示。

【老师强调 / 警告 / 易错点】
⚠️ 模式中 `(:Person {name: 'Dan'})` 的 `{name: 'Dan'}` 在 `MATCH` 子句中充当**相等性谓词**（Equality Predicate），而非数据插入。

---

【时间】 11:44–13:29  
【主题】节点与关系模式的详细语法

【核心知识点】
• 节点模式（Node Patterns）语法：必须用圆括号 `()` 包围。
• 节点变量（Node Variable）：可选的标识符，位于冒号 `:` 之前（如 `(n)`），用于在查询后续部分引用该节点。
• 节点标签（Label）：使用冒号 `:` 后接标签名指定（如 `:Person`）。
• 多标签节点：通过连续使用 `:` 指定（如 `:Person:Employee`），表示节点**同时**拥有这两个标签。
• 节点属性（Property）：在模式中使用花括号 `{}` 内的属性映射字面量（Property Map Literal）指定，格式为 `{prop: value}`。
• 属性映射在 `MATCH` 中的用途：作为相等性谓词，要求节点必须拥有指定名称和值的属性。
• 属性映射在更新（Update）中的用途：用于插入或更新节点的属性。
• 关系模式（Relationship Patterns）语法：与节点模式**非常相似**。

【重要例子 / 实验】
1. 多标签匹配示例：模式 `(:Person:Employee)` 匹配同时具有 `Person` 和 `Employee` 标签的所有节点。
2. 属性谓词示例：模式 `({name: 'Dan'})` 在 `MATCH` 中表示“属性 `name` 的值必须等于 `'Dan'`”。

【老师强调 / 警告 / 易错点】
⚠️ 节点可以有零个或多个标签，因此模式中标签的指定是**可选的**。
⚠️ 属性映射字面量 `{prop: value}` 在**读**和**写**查询中用途不同：`MATCH` 中是**谓词**，更新操作中是**数据**。
⚠️ 使用完全相同的范式（属性映射字面量）来变更（Mutate）图数据。

---

【时间】 13:35–14:48  
【主题】完整Cypher查询结构与复杂模式表达

【核心知识点】
• 基础查询结构（不同于SQL）：以 `MATCH`（要查找的内容）开始，而非 `SELECT`。
• 标准三部分：`MATCH` 子句 -> （可选的 `WHERE` 子句） -> `RETURN` 子句。
• `WHERE` 子句：用于更高级的过滤，可以使用任意相等性谓词，并能**关联**模式中多个节点的属性值。
• `RETURN` 子句：类比于SQL的 `SELECT`，是投影子句（Projection Clause）。
• `RETURN` 功能：支持SQL中的函数（如 `UPPER`）、聚合（Aggregations）、排序（`ORDER BY`）和切片（`LIMIT`/`SKIP`）。
• 复杂模式表达：使用逗号分隔多个模式片段，实现非线性的形状。
• 模式变量绑定（Binding）：不同模式片段中相同的变量名（如 `b`）会绑定到图中的**同一个**节点。

【重要例子 / 实验】
1. 完整查询示例：`MATCH (a)-[:KNOWS]->(b) WHERE a.age > b.age RETURN a.name, UPPER(b.name)`
2. T型模式（T-shape Patterns）示例：`MATCH (a)--(b), (b)--(c)`。两个模式片段通过共享的变量 `b` 连接，匹配图中一个中心节点 `b` 连接 `a` 和 `c` 的T型结构。
3. 星型模式（Star-shaped Patterns）：通过逗号分隔多个以同一节点为中心的模式片段来实现。

【老师强调 / 警告 / 易错点】
⚠️ Cypher查询从 `MATCH` 开始，这与SQL从 `SELECT` 开始的习惯不同。
⚠️ `WHERE` 子句比简单的属性映射字面量更强大，可以跨节点比较属性。
⚠️ 逗号分隔模式是表达复杂形状的关键，它提供了极大的表达灵活性（Expressivity and Flexibility）。

---

【时间】 16:14–18:57  
【主题】Cypher高级图模式匹配：可变长度路径与路径返回

【核心知识点】
• 可变长度路径匹配（Variable Length Path Matching）/ 传递闭包（Transitive Closure）：是Cypher区别于SQL的强大特性。
• 语法1：`-[:FRIEND*]->`。`*` 表示遍历 `FRIEND` 关系**一次或多次**，方向为出边（Outgoing）。
• 语法2：`-[:FRIEND*2..4]->`。`*2..4` 表示**有界**传递闭包，遍历 `FRIEND` 关系**最少2次，最多4次**。
• 语法3：`-[:LIKES|:HATES*]->`。`|` 表示关系类型的**并集**（Union），可匹配 `LIKES` 或 `HATES` 关系，`*` 表示一次或多次。
• 无限制：关系类型并集的数量没有限制。
• 路径返回（Returning Paths）：Cypher可以返回整个路径作为结果，这是SQL目前不具备的。
• 路径变量：使用 `p = (start)-[...]->(end)` 将路径赋值给变量（如 `p`）。
• 路径函数：例如 `nodes(p)` 返回路径中的所有节点，`relationships(p)` 返回所有关系。
• 路径操作：可以对路径进行排序，例如 `ORDER BY length(p)`。

【重要例子 / 实验】
1. 可变长度示例1：`MATCH (me)-[:FRIEND*]->(fof)` 查找 `me` 的所有朋友、朋友的朋友等（任意深度）。
2. 有界深度示例2：`MATCH (me)-[:FRIEND*2..4]->(fof)` 查找 `me` 的2到4度朋友。
3. 多关系类型示例3：`MATCH (me)-[:LIKES|:HATES*]->(other)` 查找通过一系列 `LIKES` 或 `HATES` 关系可达的节点。
4. 路径返回示例：`MATCH p = (a)-[:KNOWS*]->(b) RETURN p, length(p) ORDER BY length(p)` 返回所有路径并按长度排序。

【老师强调 / 警告 / 易错点】
⚠️ 在SQL中模拟可变长度路径需要使用递归公共表表达式（Common Table Expressions, CTEs）或多重 `UNION`，但会非常繁琐（Cumbersome）。
⚠️ 路径返回时，变量 `p` 包含节点和边的交替序列：`[node, edge, node, edge, ...]`。
⚠️ 可变长度路径的遍历受图中实际边数的限制。

---

【时间】 20:03–21:27  
【主题】Cypher查询的线性组合与WITH子句

【核心知识点】
• 线性组合（Linear Composition）：Cypher查询具有**自上而下**（Top-down）的流式处理逻辑。
• 基本规则：查询必须以 `RETURN` 子句结束。
• `WITH` 子句：用于分解复杂查询，实现**中间投影**（Intermediate Projection），类似于 `RETURN` 但非最终输出。
• `WITH` 的用途1：在查询中途进行聚合等操作。
• `WITH` 的用途2：混合读取（`MATCH`）和写入操作。
• `WITH` 的工作原理：接收前一个子句产生的**绑定表**（Binding Table），并选择性地将变量传递到后续子句。
• `WITH` 的“门控”效应：`WITH` 子句中未包含的变量，在后续子句中**不可用**。

【重要例子 / 实验】
1. 查询分解示例：
   - 第1行：`MATCH (me:Person)-[:FRIEND]->(f)` 生成包含 `me` 和 `f` 的绑定表。
   - 第2行：`WITH me, count(f) AS friendsCount` 对每个 `me` 聚合计算朋友数，并只将 `me` 和 `friendsCount` 传递下去。
   - 第3行：后续的 `MATCH` 只能使用 `me` 和 `friendsCount` 变量，无法再访问原始的 `f`。
2. 绑定表流转：数据像管道一样，从一个子句“流”到下一个子句。

【老师强调 / 警告 / 易错点】
⚠️ `WITH` 子句是控制查询流和数据可见性的关键。
⚠️ `WITH` 子句中投影的变量（如 `me`, `friendsCount`）是后续操作的唯一输入，其他变量被“过滤”掉。
⚠️ 这是混合读写的常见模式：先用 `MATCH` 和 `WITH` 定位数据，再用后续子句进行更新。

【时间】 21:33–22:36  
【主题】WITH子句的变量可见性与查询部分（Query Parts）概念

【核心知识点】
• `WITH` 子句的变量可见性规则：未在 `WITH` 语句中写入的变量，在后续查询中**不再可见**。
• 查询流程示例：`MATCH (me:Person {name: $param})-[:FRIEND]->(f) WITH me, count(f) AS friendsCount MATCH (me)-[:ENEMY]->(e) RETURN friendsCount, count(e) AS enemyCount`。
• 线性组合（Linear Composition）的本质：每个子句（Clause）像一个函数，接收一个表（绑定表），通过添加行或列来转换它，然后传递给下一个子句。
• 查询部分（Query Parts）：`WITH` 子句将查询划分为不同的“查询部分”（Query Parts）。
• 示例划分：`MATCH` 子句（第1行）构成一个查询部分；`WITH` 之后（第3、4行）构成另一个查询部分。
• `WITH` 的作用：像“胶水”一样连接不同的查询部分。

【重要例子 / 实验】
1. 复杂查询分解示例：
   - 查询部分1：`MATCH (me:Person {name: $param})-[:FRIEND]->(f)` 生成 `me` 和 `f` 的绑定表。
   - `WITH` 子句：`WITH me, count(f) AS friendsCount` 执行聚合，只传递 `me` 和 `friendsCount`。
   - 查询部分2：`MATCH (me)-[:ENEMY]->(e) RETURN friendsCount, count(e) AS enemyCount` 使用查询部分1传递下来的 `me` 进行新的匹配。
2. 结果：返回每个特定名字的 `Person` 的朋友数量和敌人数量。

【老师强调 / 警告 / 易错点】
⚠️ 必须在 `WITH` 子句中显式列出需要传递的变量，否则它们会“丢失”。
⚠️ `WITH` 子句是控制数据在查询部分之间流动的“地平线”（Horizon）。

【其他细节 / 补充说明】
• 这种“自上而下”的编写和阅读顺序，借鉴了现代编程语言范式，受到开发社区的欢迎。

---

【时间】 23:00–23:45  
【主题】图形数据模型在复杂领域（如流行病学）的适用性

【核心知识点】
• 应用实例：该复杂查询示例最初灵感来源于2009年英国的H1N1危机数据收集工作。
• 核心观点：图形非常适合对复杂领域（Complex Domains）进行建模。
• 表达能力：用寥寥数行Cypher代码，即可表达非常复杂的查询。

【重要例子 / 实验】
1. 领域适用性证明：使用图形对流行病学中的事件、人员、地点等复杂关系进行建模。
2. 查询效率：在图形模型中，针对此类复杂关系的查询表达非常简洁。

【老师强调 / 警告 / 易错点】
⚠️ 课程中因时间关系未详细解析该复杂查询的具体代码。

---

【时间】 23:45–24:08  
【主题】Cypher与SQL在表达可变长度路径时的对比

【核心知识点】
• 对比焦点：表达可变长度路径（Transitive Closure / Variable Length Paths）的能力。
• Cypher优势：语法简洁，使用 `-[:REL_TYPE*]->` 等模式直接表达。
• SQL劣势：需要使用递归公共表表达式（CTEs）等结构，代码**更长**，编写、理解和维护时间**更多**。

【重要例子 / 实验】
1. 对比实验：实现相同的“查找N度关系”查询。
   - Cypher版本：代码行数少，意图清晰。
   - SQL版本：代码冗长，结构复杂。

【老师强调 / 警告 / 易错点】
⚠️ SQL中模拟图查询，尤其在处理递归关系时，会非常繁琐。
⚠️ Cypher在图查询的表述效率（Expressiveness）上具有明显优势。

---

【时间】 24:16–25:00  
【主题】Neo4j Cypher查询引擎架构与新增算子

【核心知识点】
• Neo4j查询引擎流程：与传统关系型数据库引擎**非常相似**。
• 标准流程步骤：
  1. 查询字符串（Query String）输入。
  2. 语义分析（Semantic Analysis）生成抽象语法树（Abstract Syntax Tree, AST）。
  3. 基于数据库维护的统计信息（Statistics），通过查询优化器找到成本最低的逻辑计划（Logical Plan）。
  4. 将最优逻辑计划转换为物理计划执行操作符树（Tree of Execution Physical Planning Operators）。
  5. 执行查询。
• 图形数据库特有操作符（Operators）：在标准关系型操作符之外，增加了**一两个额外操作符**。
• 新增操作符功能：专门用于实现从某个节点**向外扩展**（Expanding Outwards）的图遍历操作。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 图查询引擎的核心架构并非全新设计，而是建立在成熟的关系数据库引擎技术之上。
⚠️ 关键创新点在于为图遍历这一核心操作设计了专用物理操作符。

---

【时间】 25:06–25:55  
【主题】Open Cypher项目、TCK及其对生态系统的影响

【核心知识点】
• Open Cypher项目目标：将Cypher语言推广到尽可能多的图数据库实现中。
• 提供的语言构件（Language Artifacts）：包括语法（Grammars）、形式语义（Formal Semantics）。
• 技术兼容性工具包（Technology Compatibility Kit, TCK）：包含**超过2000个**测试用例。
• TCK作用：确保不同实现严格遵循Cypher语义，极大地推动了语言实现。

【重要例子 / 实验】
1. 生态影响：在Open Cypher项目网站上可以找到完整的实现者列表，其中包含许多非Neo4j的Cypher实现。
2. TCK测试示例：展示了一个具体的TCK测试用例（未详述内容），用于验证实现是否符合规范。

【老师强调 / 警告 / 易错点】
⚠️ TCK是保证不同Cypher实现之间语义一致性的关键工具。

---

【时间】 26:01–27:20  
【主题】GQL（图形查询语言）标准化的背景与意义

【核心知识点】
• GQL全称：Graph Query Language。
• 标准化机构：ISO/IEC。
• 标准化动机（2019年前）：随着图数据库厂商增多，出现了多种具有大量交集但又不尽相同的查询语言（如Cypher, Gremlin, PGQL），这对行业不利。
• 标准化目标：融合各语言共性及各语言特有的优秀功能，创建统一的标准化图查询语言。
• 历史意义：GQL是自1987年SQL诞生以来，第一个全新的国际标准数据库语言项目。
• 与以往的区别：过去的XML等新范式查询语言都是“搭载”在SQL之上，而GQL是第一个与SQL**并列**（Sits Alongside）的独立语言。

【重要例子 / 实验】
1. 语言融合示例：GQL汲取了Cypher、Gremlin、PGQL等语言的优点。
2. 标准化里程碑：2019年成功通过立项投票。

【老师强调 / 警告 / 易错点】
⚠️ 在GQL之前，图查询领域存在语言碎片化（Fragmentation）问题。
⚠️ GQL的诞生标志着图数据库查询语言进入标准化时代。

---

【时间】 27:26–28:46  
【主题】SQL PGQ扩展与GQL的关系及未来规划

【核心知识点】
• SQL PGQ扩展全称：SQL Property Graph Query Extensions。
• PGX发布时间：计划于**2022年**发布，作为SQL的新组成部分。
• PGQ核心功能：允许在底层关系数据库上**虚拟化**（Virtualize）一个图。用户可以从表映射出虚拟图，并使用与GQL核心相同的查询能力进行查询。
• GQL发布时间：同样计划于**2022年**发布。
• 语言共性：GQL和SQL PGQ将**共享**模式匹配（Pattern Matching）和读图（Reading of Graphs）的核心能力，这部分深受Cypher影响。
• GQL额外功能：包括为多图设计的DML、创建视图（Views）、图投影（Graph Projections）、图模式（Graph Schema）管理等。
• 未来GQL规划：以图为基础，进一步支持流图（Streaming Graphs）、时序图（Temporal Graphs）等。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ SQL PGQ和GQL由重叠的专家团队共同开发，确保核心功能一致。
⚠️ GQL的功能范围远不止于读图，还包括完整的数据操作和模式管理。

---

【时间】 28:52–31:38  
【主题】GQL及Cypher未来扩展的核心特性

【核心知识点】
• 特性1：路径模式重复（Repetition of Path Patterns）。不仅可重复边标签，还可重复**整个模式**。
  - 类比：类似于SPARQL 1.1的属性路径（Property Paths），但会同时考虑节点标签和属性谓词。
• 特性2：可配置的模式匹配语义（Configurable Pattern Matching Semantics）。可选择：
  - 节点同构（Node Isomorphism）
  - 边同构（Edge Isomorphism）
  - 同态（Homomorphism）
  不同领域（Domains）需要不同的语义。
• 特性3：路径输出修饰符（Path Pattern Output Modifiers）。例如：`ALL PATHS`, `ALL SHORTEST PATHS`, `ANY SHORTEST PATHS`。
• 特性4：图形化数据类型（Graph-related Data Types）。包括：`NODE`, `EDGE`, `PATH`, `GRAPH`。同时支持嵌套数据（Nested Data）类型。
• 特性5：图模式（Graph Schema）。Cypher传统上是无模式（Schema-free）的，但成熟领域、需要数据治理（Data Governance）或数据质量（Data Quality）的领域需要模式。
• 特性6：多命名图管理与图组合操作（Multiple Named Graphs Management and Graph Composition）。
  - 功能：引用和管理多个命名图，进行图投影，以及跨多个图的组合操作（Combinatorial Operations）以生成新图（如求子图）。
  - 目标：支持建立复杂的工作流（Workflows），实现组合性（Compositionality），使一个查询的输出可作为另一个查询的输入。

【重要例子 / 实验】
1. 路径模式重复示例：未给出具体代码，但说明其评估方式类似SPARQL属性路径。
2. 模式匹配语义选择示例：社交网络分析可能使用同态以发现所有可能连接，而金融反欺诈可能使用同构以确保路径实体严格不同。

【老师强调 / 警告 / 易错点】
⚠️ 这些扩展特性将同时成为未来GQL标准和未来Cypher版本的一部分。
⚠️ 无模式（Schema-free）是Cypher的优点，但在某些严肃应用场景下，模式（Schema）成为必须。
⚠️ 图组合操作将极大地增强语言的表达能力和灵活性。

【其他细节 / 补充说明】
• 这些工作建立在大量前人研究（“站在巨人的肩膀上”）之上，引用了许多关键论文。

【时间】 32:26–33:55  
【主题】讲者介绍与本次讲座范围限定

【核心知识点】
• 讲者合作者：Lei Peng（彭磊）与 Lei Chen（陈雷），来自香港中文大学（Hong Kong USD），是讲者以前的学生或学术后辈。
• 讲者自身工作焦点：最近几年主要集中在**属性图（Property Graphs）**，特别是**流式属性图（Streaming Property Graphs）**，但本次讲座不涉及此内容。
• 本次讲座范围：概述分布式RDF和SPARQL执行的相关工作。
• 幻灯片说明：幻灯片数量多于30分钟能覆盖的内容，讲者将跳过或快速讲解部分内容，听众可后续用幻灯片作背景资料。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 本次讲座仅涵盖**部分**分布式RDF/SPARQL内容，具体为：部分扩展方案（Scale Out）、查询分区（Query Partitioning）、基于云的解聚（Cloud-based Partial Devaluation）以及联邦系统（Federated Systems）。
⚠️ 不涵盖以下内容：集中式系统（Centralized Systems）、图式扩展方案（Graph-based Scale Out）、流式系统（Streaming Systems）。

【其他细节 / 补充说明】
• 推荐资源：Katya Hose在EDBT 2021会议上关于知识图谱的主题演讲（Keynote），预计将上传至YouTube。

---

【时间】 34:01–35:02  
【主题】RDF的应用场景、规模与增长趋势

【核心知识点】
• RDF（Resource Description Framework）是知识图谱（Knowledge Graphs）和语义网（Semantic Web）的构建块之一。
• 关联开放数据（Linked Open Data, LOD）项目：包含约**1200个**数据集。
• LOD数据规模：确切的RDF三元组（Triples）数量未知，但最佳估计超过**1000亿（100 billion）**个三元组。
• 单个大型数据集示例：UniProt（生物学知识图谱）报告其自身拥有超过**840亿（84 billion）**个三元组。
• 数据增长：LOD数据在过去10年中经历了**实质性（Substantial）**增长，且增长**相当快（Fairly Fast）**。

【重要例子 / 实验】
1. 规模估算实验：通过调研，对LOD总三元组数的“最佳猜测”超过1000亿。
2. 单点验证实验：UniProt作为单个大型数据集，其规模（840亿三元组）支持了总规模庞大的观点。

【老师强调 / 警告 / 易错点】
⚠️ 1000亿三元组的估计可能**保守（Conservative）**，因为仅UniProt一个数据集就接近这个数量级。

---

【时间】 35:15–36:25  
【主题】分布式RDF系统出现的驱动力与两大架构

【核心知识点】
• 数据管理研究者（Data Management Researchers）的核心关切：给定数据模型和查询语言后，关注**声明式查询处理（Declarative Query Processing）**的效率。
• 初始RDF系统：是**单机或集中式（Single Machine or Centralized）**的。
• 转向分布式的原因：数据集规模（Data Set Sizes）的增长。
• 分布式RDF两大架构：
  1. **扩展方案（Scale Out）**：将一个**大型RDF数据集**在多个机器上进行**分区（Partitioning）**，然后并行执行SPARQL查询。
  2. **联邦方案（Federated Solutions）**：多个独立的、由不同所有者维护的RDF数据集（每个都有自己的SPARQL端点），需要跨这些端点进行查询。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 对于声明式查询处理，**显而易见的解决方案（Obvious Solutions）通常并不高效**，因此需要数据管理社区专注于查询执行效率。

---

【时间】 36:51–38:18  
【主题】分布式SPARQL系统分类（细化视角）

【核心知识点】
• 分类细化：在Katya Hose分类（集中式、客户端-服务器、流式等）基础上，提出更细粒度的分类。
• 细化分类层级：
  1. **集中式（Centralized）**
    - **类关系型（More or Less Relational）**：采用三元组表（Triple Table）方式工作。
    - **基于图（Graph Based）**：本次讲座不讨论。
  2. **扩展方案（Scale Out）**：有多种不同替代方案。
  3. **联邦方案（Federated Solutions）**
    - 端点类型1：**SPARQL端点（SPARQL Endpoints）**，具备SPARQL查询处理能力。
    - 端点类型2：**仅存储RDF数据但无处理能力**的端点。
  4. **流式系统（Streaming Systems）**：用于RDF流式处理，已开始出现。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 本次讲座将只讨论**扩展方案中的一部分、查询分区、基于云的部分解聚以及联邦系统**。
⚠️ 再次推荐Katya Hose在EDBT 2021的主题演讲。

---

【时间】 39:06–40:09  
【主题】SPARQL核心：基本图模式（BGP）的语义与操作解释

【核心知识点】
• 讲座聚焦的SPARQL子集：**基本图模式（Basic Graph Pattern, BGP）**。
• BGP定义：仅由**三元组模式（Triple Patterns）** 构成，不含UNION、OPTIONAL等其他操作符的SPARQL查询。
• SPARQL语义本质：基于**同态（Homomorphism）** 的**子图匹配（Subgraph Matching）**。
• SPARQL操作语义（Operational Semantics）：一种理解方式是，为查询中的**每个**三元组模式，在RDF三元组库中找到所有匹配的三元组，形成列表（或表），然后对这些列表执行**连接（Joins）**操作。
• 连接类型：
  - **主体-主体连接（Subject-Subject Join）**：当两个三元组模式共享相同的主体（Subject）变量时。
  - **主体-客体连接（Subject-Object Join）**：当一个三元组模式的客体（Object）变量与另一个三元组模式的主体（Subject）变量相同时。

【重要例子 / 实验】
1. BGP查询示例：一个包含5个三元组模式的查询。
2. 操作语义模拟：为这5个模式分别生成5个匹配三元组列表，然后通过一系列连接操作（主体-主体、主体-客体）来组合结果。

【老师强调 / 警告 / 易错点】
⚠️ 幻灯片中笔误修正：描述连接操作时，“strong object join”应为 **“subject-subject join”**。
⚠️ 理解BGP的“连接”视角是后续讨论的重要基础。

---

【时间】 41:31–42:20  
【主题】SPARQL查询的常见形状（Shapes）及其对系统的影响

【核心知识点】
• SPARQL查询形状（SPARQL Query Shapes）在后续系统讨论中**非常重要（Quite a Bit）**。
• 常见查询形状分类：
  1. **星型（Star Shape）**：最常见。一个中心顶点（变量）连接出多条谓词/属性边。
  2. **树型（Tree）**
  3. **链型（Chain）**
  4. **环型（Cycle）**
  5. **复杂查询（Complex Queries）**：通常指由多个星型（如双星、三星）连接而成，但也可能包含其他形状的组合。
• 复杂查询示例：一个同时包含星型、链型和环型结构的查询。

【重要例子 / 实验】
1. 形状图示：幻灯片展示了星型、树型、链型、环型的图形化表示。
2. 复杂查询示例图：展示了一个集星型、链型、环型于一体的复杂模式。

【老师强调 / 警告 / 易错点】
⚠️ “复杂查询”通常被讨论为**多个星型查询的附着（Two Star Queries or Three Star Queries Attached to Each Other）**，但它们**不一定只是星型的组合（They Don‘t Have to Be Only Stars）**。

---

【时间】 42:26–43:27  
【主题】扩展系统的前提：图分区（分区）的目标与简单哈希方法的缺陷

【核心知识点】
• 扩展系统（Scale Out Systems）的前提：假设图已经被**分区（Partitioned）**。
• 分区目标：将数据分布在多个工作节点（Worker）上，以实现查询的并行执行。
• 分区类型：**水平分区（Horizontal Partitioning）**，也称为**分片（Sharding）**。
• 一种简单方法：对**三元组表（Triple Table）** 直接使用**简单哈希（Simple Hashing）** 进行分区。
• 简单哈希分区的问题：在执行SPARQL查询时，进行**主体-客体连接（Subject-Object Joins）** 等操作时会遇到效率问题。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 对三元组表进行简单哈希分区在处理连接查询时存在**问题（One of the Problems）**。
⚠️ 具体问题将在后续讲解（讲者的话在此处中断）。

【时间】 43:32–44:10  
【主题】简单哈希分区的问题与图分区技术引入

【核心知识点】
• 简单哈希分区（Simple Hashing Partitioning）的缺陷1：会产生**过多中间结果（Way Too Many Intermediate Results）**，导致连接成本（Join Costs）增加。
• 简单哈希分区的缺陷2：进行**跨分区连接（Inter-partition Joins）** 时，需要在分区之间**移动数据（Move Data Around）**，使问题复杂化/困难。
• 根本原因：三元组表（Triple Table）**未能捕获三元组之间的关系（Does Not Capture the Relationships Between the Triples）**。
• 解决方案转向：直接应用**图分区技术（Direct Graph Partitioning Techniques）**，将RDF数据视为图（Graph）而非单纯的表（Table）进行分区。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 基于三元组表的简单哈希方法不适用于需要高效处理连接的图查询场景。

---

【时间】 44:15–45:10  
【主题】图分区的两种通用方法及核心目标

【核心知识点】
• 图分区两种通用方法（也适用于属性图）：
  1. **边切割（Edge Cut）** / **顶点不相交（Vertex Disjoint）**：每个顶点（Vertex）仅属于一个分区，边（Edge）可能被切割。
  2. **顶点切割（Vertex Cut）** / **边不相交（Edge Disjoint）**：每条边仅属于一个分区，顶点可能被复制到多个分区。
• 图分区通用目标：
  - **负载均衡（Balanced）**：各分区大小大致相当，使各工作节点负载均衡。
  - **最小化切割**：在实现顶点/边不相交的前提下，**最小化边切割（Edge Cuts）或顶点切割（Vertex Cuts）**。
• 最小化切割的原因：被切割的边或顶点会导致**额外的通信（Extra Communication）** 或**状态维护（State Maintenance）** 开销。

【重要例子 / 实验】
无

【老师强调 / 警告 / 易错点】
⚠️ 大多数图分区技术是**与工作负载无关的（Workload Agnostic）**，即不考虑查询模式。
⚠️ 本次讲座讨论的技术都属于工作负载无关型。

---

【时间】 45:28–47:49  
【主题】顶点不相交（Vertex Disjoint）分区的具体技术、比较与缺陷

【核心知识点】
• 顶点不相交（Vertex Disjoint）分区定义：将**每个顶点（Vertex）放入一个且仅一个分区**。
• 后果：导致**边被切割（Edges to be Cut）**。
• 技术1：**基于顶点ID的哈希（Hashing on the IDs of the Vertices）**。
  - 优点：**非常均衡（Very Balanced）、非常快速（Very Fast）、简单（Simple）**。
  - 缺点：导致**大量中间结果（High Number of Intermediate Results）** 和**大量的边切割（High Number of Edge Cuts）**。
• 技术2（黄金标准）：**METIS算法族（METIS Family of Algorithms）**。
  - 核心流程：
    1. **粗化（Coarsening）**：将原图G0中的子图表示为**超顶点（Super Vertices）**，迭代粗化得到G1, G2, ... Gn。
    2. **初始分区**：当Gn足够小时，使用任意分区技术对其进行分区。
    3. **解粗化与映射（Uncoarsening and Reflecting）**：将Gn的分区结果逐步解粗化，映射回原始图G0。
• METIS算法的缺点：**计算开销非常高（Very High Computation Overhead）**，难以扩展到大型图（Doesn‘t Scale to Large Graphs）。

【重要例子 / 实验】
1. 哈希分区图示示例：使用基于顶点标签的哈希函数对示例图分区，结果产生大量虚线表示的切割边（Cuts），效果不佳。
2. 适用性分析实验：
   - 顶点不相交分区在**低度图（Graphs with Low Degrees）** 上表现良好。
   - 在**幂律图（Power Law Graphs）** 上会导致**大量切割（Many Cuts）**。

【老师强调 / 警告 / 易错点】
⚠️ 几乎所有提供顶点分区功能的系统，都将**哈希（Hashing）** 作为其工具箱的一部分。
⚠️ METIS虽为黄金标准，但其高计算开销限制了在大图上的应用。

【其他细节 / 补充说明】
• 对于RDF，减少跨分区连接的关键可能不是最小化边切割，而是最小化**谓词切割（Predicate Cuts）**。

---

【时间】 48:25–50:51  
【主题】边不相交（Edge Disjoint）分区原理、应用场景与问题

【核心知识点】
• 边不相交（Edge Disjoint）分区定义：将**每条边（Edge）放入一个且仅一个分区**。
• 后果：导致**顶点被复制（Vertices Are Replicated）**。如果属于不同分区的两条边共享一个顶点，该顶点必须在两个分区中**重复出现（Repeated）**。
• 顶点复制的隐含问题：如果这些顶点的**状态（State）** 需要在多处维护，会产生一致性问题。
• RDF场景的特殊性：在RDF中，顶点复制问题**不那么严重（Less of an Issue）**，因为RDF是简单图模型，顶点只有标签（Labels），几乎没有更新操作。
• 边不相交分区的应用场景：**广泛用于基于云的系统（Cloud-based Systems）**。
  - 具体做法：将**具有相同谓词（Predicate）** 的所有边放入一个文件，存储在HDFS上。
  - 目标：**最小化扫描（Minimize the Scans）**。通过将查询聚焦在特定谓词对应的文件上，提高扫描效率。
• 边不相交分区的优点：在**幂律图（Power Law Graphs）** 上表现良好，且**高度可序列化（Highly Serializable）**。

【重要例子 / 实验】
1. 边不相交分区图示示例：对示例图进行边不相交分区，结果中虚线顶点（Dash Vertices）表示在不同分区（如P2, P3）中复制的顶点。
2. 适用性分析实验：
   - 优点：在幂律图上表现好，执行快速。
   - 缺点（问题1）：**星型查询（Star Queries）表现不佳**。因为星型查询希望中心顶点及其所有邻边在同一个分区，而边不相交分区会将这些边拆分到不同分区。
   - 缺点（问题2）：可能导致**高顶点复制率（High Vertex Replication）**。

【老师强调 / 警告 / 易错点】
⚠️ 边不相交分区在云系统中的核心优势是能按谓词组织数据，优化扫描。
⚠️ 星型查询是边不相交分区的主要性能瓶颈。

---

【时间】 50:58–52:48  
【主题】扩展系统类型一：查询分区系统（Query Partitioning Systems）原理

【核心知识点】
• 查询分区系统（Query Partitioning Systems）前提：数据图**已预先分区（Already Partitioned）**，分为D1到D6等多个分区。
• 核心思想：对输入的**SPARQL查询（Query）** 进行**分区（Partition）**，生成**子查询（Subqueries）**。
• 分区目标：以**最小化跨分区连接（Minimize Inter-partition Joins）** 的方式划分查询，使得每个子查询能**尽可能独立地（As Independently as Possible）** 在单个工作节点上执行。
• 问题本质：这是**分布式查询处理与优化（Distributed Query Processing and Optimization）** 问题，与关系型系统中的问题**非常类似（Very Analogous）**。
• 关键耦合：查询分解（Query Decomposition）与数据分区（Data Partitioning）之间存在**高度耦合（High Degree of Coupling）**。
  - 路径A：先确定数据分区方式，再基于此决定如何分解查询。
  - 路径B：先确定期望的查询分解特性，再以此为目标设计数据分区策略。

【重要例子 / 实验】
1. 分区数据图示示例：一个图被分为两个分区（琥珀色顶点和蓝色顶点），绿色虚线边表示**边切割（Edge Cuts）**，即分区间的通信发生处。

【老师强调 / 警告 / 易错点】
⚠️ 查询分区系统的核心挑战在于如何协调数据布局与查询分解，以最小化昂贵的跨分区连接。


【时间戳】 53:19 – 55:00

【核心主题】查询分区系统示例：基于顶点复制的S形系统

【重点内容】
• 系统流程：
  1. **基线分区（Base Partitioning）**：使用METIS等方法进行初始图分区（Vertex Disjoint）。
  2. **顶点复制（Vertex Replication）**：使用**n-hop**复制策略扩展每个分区。
    - 过程：在每个分区（如“琥珀色”分区），向相邻分区（如“蓝色”分区）**“伸出（Reach Out）”**，复制**1跳可达（1-hop Reachable）** 的顶点到本分区。
    - 参数 `n`：复制跳数，`n` 值越高，**复制成本（Replication Cost）** 越高，但能支持更多查询的独立执行。
  3. **查询处理**：
    - 计算查询 `Q` 的**半径（Radius）**：从查询模式中心到其边界的距离。
    - 决策：如果查询半径 `> n`，则将查询**切分为多个子查询（Partition it into Several Subqueries）**，确保每个子查询半径 `≤ n`。
    - 执行：每个子查询在相应分区上独立执行。

【关键例子 / 实验 / Demo】
• 图示说明：在已分为琥珀色和蓝色分区的图上，每个分区通过复制对方分区1跳远的顶点（扩展边界）来减少跨分区连接。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ `n` 的选择是权衡：增大 `n` 可提升查询独立性，但增加复制成本；极端情况（`n` 极大）等于不分区，不可取。

---

【时间戳】 55:01 – 56:35

【核心主题】查询分区系统另一示例：基于语义哈希的顶点块（Vertex Block）方案

【重点内容】
• 数据分区方法：**语义哈希（Semantic Hashing）**。
  1. **三元组建组（Triple Groups）**：根据共享相同**主语（Subject）、宾语（Object）或谓词（Predicate）** 将三元组分组，形成 **S-组、O-组、P-组**。
  2. **哈希分配**：使用哈希函数将每个三元组分配到机器。
  3. **允许复制（Allow Replication）**。
• 查询处理思路（类比）：
  - 场景：查询跨越三个分区（P1, P5等），无法独立执行。
  - 解决方案：通过**稍微扩展（Extend）** 每个分区（如扩展P1和P5的边界），使原本需要跨分区连接的查询能在单个扩展后的分区内独立执行。
• 本质：与前一个系统（S形）的核心思想（通过复制/扩展分区减少跨分区连接）**并无太大不同（Not Very Different）**，区别在于数据分区和查询分区的具体方法略有变化。

【关键例子 / 实验 / Demo】
• 思维示例：一个查询横跨P1、P5等分区。若将P1的边界向外扩展一点，该查询中与P1相关的部分便可独立执行；对P5同理。

---

【时间戳】 56:43 – 58:49

【核心主题】讲者团队新工作：最小化谓词切割而非边切割

【重点内容】
• **核心洞见（Recognition）**：先前工作旨在最小化**边切割（Edge Cuts）**，但真正导致跨分区连接（Inter-partition Joins）的并非边切割本身。
• **新指标**：应最小化**谓词切割（Predicate Cuts）**，甚至可以**以增加边切割为代价（At the Cost of Increasing Edge Cuts）**。
• 原理：如果被切割的所有边都涉及**同一个谓词（Single Predicate）**（例如都是 `bornOn` 或 `residentIn`），那么能独立执行的查询类别会**大幅增加（Increases Quite a Bit）**。
• 方法框架：
  1. **粗化（Coarsen）**：类似METIS，但关键在于粗化时**内部谓词（Internal Predicate）** 的选择。
  2. **超级顶点（Super Vertices）形成**：使用基于**弱连通分量（Weakly Connected Components）** 的**贪心算法（Greedy Algorithm）** 选择谓词来形成超级顶点。
  3. **分区与解粗化**：对粗化图进行分区，然后解粗化（Uncoarsen）映射回原图。
  4. **查询处理**：有一套处理查询的方法论（未详述）。
• 状态：工作**尚未发表（Not Published Yet）**，正在投稿中（Under Submission）。
• 效果：能提供**相当好的性能（Fairly Good Performance）**。

【关键例子 / 实验 / Demo】
• 思想实验：被切割的边如果都属于同一个谓词（如 `bornIn`），那么涉及该谓词的星型查询就能在一个分区内完成，尽管边切割数量可能很多。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 颠覆了传统图分区最小化边切割的目标，提出谓词切割是更关键的指标。

---

【时间戳】 58:54 – 1:00:18

【核心主题】查询分区方法的评价、局限与关系型方法的对比

【重点内容】
• 查询分区方法优点：**高性能（High Performance）**，非常适合并行化集中式RDF数据。
• 查询分区方法缺点/挑战：
  1. **质量构成不易（Quality Composition is Not Easy）**。
  2. **查询分解困难（Query Decomposition is Difficult）**，这在关系型案例中亦然。
  3. **查询分解与数据分解紧密耦合（Very Tightly Integrated）**。
• 关系型分布式查询处理的成熟流程对比：
  1. 查询分解（Query Decomposition）
  2. 数据本地化（Data Localization）
  3. 生成代数查询树（Algebraic Query Tree）
  4. 根据数据分布对查询树进行分区以最小化连接
  5. 创建并优化分布式查询计划（Distributed Query Plan）
  6. 在各站点执行本地查询
  7. 执行分布式执行计划以整合结果
• 关键差距：在基于图处理的查询分区领域，**没有这样成熟的工作（Not This is Really Not Done）**。
• 根本原因之一：缺少为SPARQL**充分发展的代数（Well-Developed Algebra）**。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 图查询的分布式处理可以借鉴但尚未充分利用关系型数据库成熟的分布式查询优化技术栈。

---

【时间戳】 1:00:36 – 1:02:48

【核心主题】扩展系统类型二：部分查询评估（Partial Query Evaluation）

【重点内容】
• 前提：RDF数据已分区，但**不对查询进行分区（We Don‘t Partition the Query）**。
• 核心技术：借用编程语言领域的**部分求值（Partial Evaluation）** 技术。
  - 核心思想：将函数 `f(x)` 重写为 `f'(s, d)`，其中 `s` 是已知输入，`d` 是未知输入。
  - 步骤：先仅对已知输入 `s` 执行 `f‘` 得到部分结果，再通过另一个函数处理未知部分 `d` 得到最终答案。
• 在图查询中的映射：
  - **已知输入（Known Inputs）**：查询本身 + 各分区的**扩展顶点（Extended Vertices）**（即位于跨分区边末端的顶点）。
  - **未知部分**：跨越分区的匹配（Crossing Matches）。
• 执行流程：
  1. **本地评估（Local Evaluation）**：将查询发送到每个分区，分区计算**部分结果（Partial Results）**，但这不是最终结果，因为缺少跨分区匹配。
  2. **组装阶段（Assembly Phase）**：通过一个**连接操作符（Join Operator）** 从这些部分结果组装出最终结果。
• 组装架构选项：
  - **集中式（Centralized）**：将部分结果发送回查询发起处进行组装。
  - **分布式连接处理（Distributed Join Processing）**。

【关键例子 / 实验 / Demo】
• 技术类比：将图查询视为函数，已知输入是查询和分区的边界信息，通过部分求值技术分步求解。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 此方法性能高，无需处理查询分解难题，但需要**修改每个站点的RDF系统（Modify the RDF Systems at Each Site）** 以支持部分求值技术。

---

【时间戳】 1:03:14 – 1:05:19

【核心主题】扩展系统类型三：基于云的解决方案（Cloud-based Solutions）

【重点内容】
• 执行模式：将SPARQL查询作为**MapReduce作业（MapReduce Jobs）** 运行，属于典型的**数据并行执行（Data Parallel Execution）**。
• 核心思想：查询操作被实现为MapReduce任务。
• 数据分区：通常采用**基于边的分区（Edge-based Partitioning）**。
• 具体案例：**HadoopRDF**。
  1. **数据组织**：
    - 按**谓词（Predicate）** 分割：所有具有相同谓词的三元组存入一个文件。
    - 可进一步根据**客体（Object）** 部分进行细分。
  2. **查询执行**：
    - 为查询中的每个**三元组模式（Triple Pattern）** 选择一个相应的文件。
    - 将每个三元组模式在该文件上的扫描作为一个MapReduce作业执行。
    - 最后通过一个MapReduce连接作业整合所有结果。
• 优点：
  - **高度可扩展（Highly Scalable）**。
  - **天生容错（Inherently Fault Tolerant）**，得益于MapReduce框架。
• 缺点/局限：
  - 性能受限于MapReduce本身的能力。
  - 产生的**中间关系（Intermediate Relations）** 需要写回HDFS，导致大量I/O。
  - 连接操作需要作为一个单独的MapReduce作业运行，意味着需要再次从HDFS读取数据。
  - 任何优化都必须在MapReduce平台**之外（Outside）** 进行。

【关键例子 / 实验 / Demo】
• HadoopRDF示例：将RDF数据按谓词组织成文件（如所有 `hasName` 三元组在一个文件），查询时每个三元组模式扫描对应文件，最终进行MapReduce连接。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 基于云/MapReduce的方案受其批处理、高I/O开销的特性限制，优化空间有限。推荐阅读相关书籍以深入了解。

【时间戳】 1:05:30 – 1:07:50

【核心主题】联邦查询系统（Federated Query Systems）的基本架构与查询执行流程

【重点内容】
• 系统前提：与扩展系统相反，拥有**一组（A Set of）** RDF数据源 `D_sub_i`，每个都是**SPARQL端点（SPARQL Endpoint）**（即能执行SPARQL查询）。
• 核心思想：**数据集成（Data Integration）**，自底向上（Bottom-up）整合多个独立数据源。
• 核心组件：**控制站点（Control Site）**，维护关于各数据源访问模式等的**元数据（Metadata）**。
• 标准执行流程（典型步骤）：
  1. 控制站点接收查询。
  2. 控制站点进行**查询分解（Query Decomposition）**。
  3. 控制站点**选择（Selects）** 每个查询子部分（`qi`）应在哪个数据源上执行。
  4. 在各个数据源上进行**本地评估（Local Evaluation）**。
  5. 将部分结果返回。
  6. 在控制端**连接（Join）** 所有部分结果以得到最终答案。

【关键例子 / 实验 / Demo】
• 查询分解示例：
  - 给定一个包含多个三元组模式的查询。
  - 分析每个模式可执行的数据源：模式1和模式2可在 **GeoNames** 执行，模式3可在多个源中选择一个，模式4可在 **New York Times** 执行。
  - 据此将查询分解为子查询 `Q1`、`Q2`、`Q3`，分别发送到对应端点执行，最后组合结果。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 该流程的核心是“分解 -> 分配执行 -> 组合结果”。

---

【时间戳】 1:07:50 – 1:09:10

【核心主题】联邦系统的变体、优势与关键挑战（端点不可靠性）

【重点内容】
• 非SPARQL端点的处理：使用**中介器（Mediators）**。
  - 中介器包含**包装器（Wrappers）**，使非SPARQL源**假装（Pretend）** 成SPARQL端点。
• 实际案例：**UniProt** 是一个联邦查询服务的例子，它查询多个UniProt数据存储，属于**面向服务（Service Oriented）** 的联邦查询执行。
• 联邦系统优势：采用数据集成方法，**按原样（As They Are）** 接受数据集，无需对数据进行额外处理。
• 联邦系统关键挑战：SPARQL端点的**不可靠性（Notoriously Unreliable）**。
  - 具体数据：研究显示，**在任何给定时间，高达64%的SPARQL端点可能处于离线状态（Up to 64 Percent of These SPARQL Endpoints Are Offline）**。
  - 影响：提交查询时，目标端点可能离线。
  - 需求：需要能够应对此情况的**容错查询处理技术（Fault Tolerant Query Processing Techniques）**。
• 中介器的缺点：实现中介器是**繁重的任务（Heavy Duty）**。

【关键例子 / 实验 / Demo】
• UniProt示例：作为一个联邦服务，它整合了多个物理上独立的UniProt数据存储，对外提供统一的查询接口。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 端点高离线率是联邦系统实际部署中的严重现实问题，必须在系统设计中考虑容错。

---

【时间戳】 1:09:34 – 1:11:23

【核心主题】分布式RDF/SPARQL技术现状总结与开放问题

【重点内容】
• 总体评价：该领域已有大量工作，但技术**不如分布式关系数据管理成熟（Not as Mature as Distributed Relational Data Management）**。
• 成熟度不足的原因分析：
  1. **社区侧重不同**：
    - **语义网社区（Semantic Web Community）**：更关注**功能性（Functionality）**，对性能（Performance）关注较少。只要查询能执行，通常即满足。
    - **数据管理社区（Data Management Community）**：近年更多聚焦于**属性图（Property Graphs）** 而非RDF图。
  2. **查询语言支持局限**：大多数工作仅考虑**基本图模式（BGP， Basic Graph Pattern）**。
    - **完整SPARQL 1.1** 包含的 `OPTIONAL`、`UNION`、聚合（Aggregation）等特性**尚未得到良好处理（Not Well Handled Yet）**。
  3. **理论基础薄弱**：为SPARQL定义的**代数（Algebra）** 刚开始出现（有近期论文），但其有效性尚待评估（讲者正在研究中）。代数的成功是未来进步的前提。
• 主要开放研究问题（Open Problems）：
  1. **使用视图（Using Views）** 进行优化。
  2. **基于视图的优化（View Based Optimization）**。
  3. **多查询优化（Multi-Query Optimization）**。
  4. **基于成本的优化（Cost-Based Optimization）**。
  5. **动态数据处理**：现有工作仅考虑**静态RDF图（Static RDF Graphs）**。
    - 开放问题：当图随时间演化时，如何进行**增量查询处理（Incremental Query Processing）** 以适应变化尚属未知。

【关键例子 / 实验 / Demo】
• 无具体实验，但列举了关键的技术瓶颈和待研究方向。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 分布式RDF处理在优化理论、对完整语言特性的支持以及对动态数据的处理方面，存在显著的研究空白。

---

【时间戳】 1:11:55 – 1:13:24

【核心主题】并行化（扩展系统与联邦系统）的必要性场景

【重点内容】
• 并行化的两种主要场景：
  1. **联邦系统场景（Federated Case）**：
    - 驱动因素：数据所有者希望**保持数据所有权（Maintain Ownership of Their Data）**。
    - 表现：他们愿意在其数据上运行查询并成为联邦的一部分，但**不愿放弃数据控制权（Not Willing to Let Go of Their Data）**。
  2. **扩展系统场景（Scale Out Case）**：
    - 驱动因素：数据集规模导致性能瓶颈。
    - 具体情形：
      a. **数据量过大**：无法存储在单台机器上。
      b. **计算过重**：尤其是并发查询运行时，需要获得**查询内并行（Intra-Query Parallelism）** 和**查询间并行（Inter-Query Parallelism）**。
• 补充观点（来自提问者）：**商用硬件（Commodity Hardware）** 通常比**垂直扩展系统（Vertically Scaling Systems）** 更便宜。

【关键例子 / 实验 / Demo】
• 无具体例子，是对应用场景的概括。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 并行化不是目的，而是解决特定约束（数据主权、性能瓶颈）的手段。

---

【时间戳】 1:13:33 – 1:14:39

【核心主题】关于使用Cypher构建基于知识图谱的问答系统（Q&A）的回应

【重点内容】
• 问题背景：如何设计Cypher查询来查询知识图谱以构建问答系统，特别是当问题以英文提出时。
• 核心回应：Cypher本身**无法直接处理自然语言问题（Not Possible）**。
• 必要技术栈：需要一个**自然语言处理库（Natural Language Processing Library）** 作为前端。
• NLP库的作用：
  1. 处理书面或口语英语。
  2. **提取动词和名词（Pull Out Verbs and Nouns）**。
  3. 将它们**映射（Map）** 到Cypher查询模式。
• 举例说明：对于问题“Find me all people who have eaten at a restaurant in San Francisco”，可以尝试围绕其中实体和关系构建基本模式。
• 现状评估：该领域（从自然语言到Cypher）的探索**尚处于非常早期阶段（At a Very Early Stage）**，仅知有少量团队正在研究。

【关键例子 / 实验 / Demo】
• 自然语言到查询模式映射示例：将英文句子“Find me all people who have eaten at a restaurant in San Francisco”中的元素（people, eaten at, restaurant, San Francisco）映射为图查询中的节点和边。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 目前不存在不借助额外NLP层而直接用Cypher实现问答系统的方法。


【时间戳】 1:15:13 – 1:17:09

【核心主题】回答关于“跨源查询示例如何执行”及“数据源发现”问题

【重点内容】
• RDF查询中的**前缀（Prefix）**：类似于XML命名空间，用于缩写长URI。
  - 示例：前缀 `g` 指代 GeoNames， `y` 指代 New York Times。
• 跨源查询示例（来自早期课程）：查询“Show me all the people who were born in Winterthur who also died there”。
  - 挑战：此类问题的数据**不会位于单一位置（Not Going to Find Data in One Location）**。
• 关于“是否存在真实的联邦查询系统”的讨论：
  - **数据源发现问题（Which Sources I Need to Go To）**：这**并非已解决的问题（Not a Solved Problem）**，且对于数据管理社区是外部问题。
  - 类比：如同SQL，你需要先知道**模式（Schema）** 才能编写正确的查询，然后才考虑执行。
  - 定位：**这是一个活跃且重要的独立研究领域（An Active and Important Research Domain on Its Own）**。

【关键例子 / 实验 / Demo】
• 示例查询解释：“查找所有在温特图尔出生并在该地去世的人”涉及跨越不同数据源的出生和死亡信息。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 跨源查询的首要难题是**数据源发现**，这先于查询执行优化。

---

【时间戳】 1:17:09 – 1:18:42

【核心主题】讨论自然语言接口、UniProt联邦示例及其查询模式

【重点内容】
• **SPARQL查询编写的难度**：即使是已知数据源，编写复杂SPARQL查询也**非易事（Not an Easy Task）**。
• 一个解决方案方向：**面向SPARQL的自然语言接口（Natural Language Interfaces to SPARQL）**，可能成为解决途径。
• **UniProt知识图谱（UniProt Knowledge Graph）** 作为具体联邦系统实例：
  - 规模：整合了**150个RDF数据集（Combines 150 RDF Data Sets）**。
  - 查询方式：允许在其网站提交SPARQL查询，该查询会**实时（In Real Time）** 分发到这150个源。
  - 局限性：用户仍需**大致了解（Know Something About）** 每个数据源提供的内容。
• 个人体验分享：讲者尝试过UniProt网站上的**示例查询（Sample Queries）**，但未尝试自行构建查询，因缺乏足够生物学知识。

【关键例子 / 实验 / Demo】
• UniProt实时查询演示：用户可访问UniProt网站，运行其提供的示例查询或尝试构建自己的查询，系统会实时执行并返回结果。

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 即使存在如UniProt这样的联邦系统，用户仍面临“需要了解数据源内容”的知识门槛。
⚠️ 编写有意义的领域查询（如生物学）需要相应的领域知识。

---

【时间戳】 1:18:42 – 1:19:34

【核心主题】回答关于Neo4j的分布式与并行技术

【重点内容】
• Neo4j的分布式版本：企业版中的 **Fabric** 功能。
• Fabric的核心技术：采用**边不相交分区（Edge Disjointed Partitioning）** 的变体（Variant）将图分布到多个数据库。
• 并行处理（Parallel Processing）：Neo4j工程部门正在进行相关的研究和调查（Investigating）。
• 资源：提供Fabric的链接以供进一步了解。

【关键例子 / 实验 / Demo】
无

【注意事项 / 易错点 / 老师特别强调的内容】
⚠️ 讲者本人未直接参与Fabric的开发工作。

---

【时间戳】 1:19:45 – 1:20:42

【核心主题】课程总结与预告

【重点内容】
• 课程结束时间：5:50。
• 对两位嘉宾的感谢：感谢其对Cypher和SPARQL处理的**详细且深入的探讨（Detailed and Thorough Deep Dive）**。
• 核心印象：对解决**可扩展性问题（Scalability Concerns）** 的分布式与并行查询处理技术印象深刻。
• 技术重要性：随着数据集变大，这些**可扩展查询评估技术（Techniques for Scalable Query Evaluation）** 将愈发重要。
• 下周课程预告：主题为 **“如何设计知识图谱的模式（How to Design the Schema of a Knowledge Graph）”**。

【关键例子 / 实验 / Demo】
无

【注意事项 / 易错点 / 老师特别强调的内容】
无


