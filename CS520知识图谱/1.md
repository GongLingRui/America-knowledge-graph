视频链接:https://www.youtube.com/watch?v=FRcF6sh8sI0&list=PLDhh0lALedc5paY4N3NRZ3j_ui9foL7Qc&index=1


【时间戳】 00:00 – 04:10

【核心主题】研讨会介绍、动机及课程结构概述。

【重点内容】
• 研讨会由 Naren 和 Mike 共同组织，主题为知识图谱。
• 组织动机：知识图谱被广泛应用于**网络搜索、问答、数据集成**，并成为**NLP、视觉及机器学习算法**首选的输出表示形式。
• 目标：传授知识图谱的**基本思想、概念、理论和应用**。
• 重要性：美国国家科学基金会（NSF）去年资助了约 **20个** 知识图谱项目。
• 课程结构（2021年春季）：
    • **周二**：课程核心内容，基于 **2020年系列30位受邀演讲者** 观点的**综合与总结**，形成课程笔记。
    • **周四**：邀请来自学术界和工业界的嘉宾进行演讲，通常为**两场30分钟的报告**，随后是问答环节。
    • 课程采用**两次18分钟**的会议形式（周二和周四），而非传统的单次两小时会议。
• 考核要求（斯坦福大学获得学分的学生）：
    • 完成所有 **10次** 周二课程的测验。
    • 提交 **10次** 周四课程中任意 **8次** 的书面总结。
• 这是一个**1个学分**的课程，要求较轻。

【关键例子 / 实验 / Demo】
• 无

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 周二课程内容主要是对去年系列讲座的综合，而非全新的嘉宾演讲。

---

【时间戳】 04:11 – 09:46

【核心主题】知识图谱的数学定义、构成要素及其含义的多种定义方式。

【重点内容】
• 知识图谱定义：一个**有向标签图**，其中**节点和边具有明确定义的含义**。
• 核心是数学上的有向标签图，重点在于**定义节点和边的含义**。
• 不同的数据模型对节点和边有不同称呼：
    • **主语-谓语-宾语**三元组。
    • **实体-关系-实体**三元组。
    • **类层次结构**：节点是类，边标为“子类”或“子集”关系。
• 含义定义示例：节点“Art”和“Bob”代表现实世界的人；边“朋友”可以定义为“Art在Facebook上向Bob发送了好友请求且Bob接受了该请求”。
• 对于抽象概念（如类），含义通常通过**文本描述**定义，更复杂的情况下可使用**逻辑语言**进行形式化规范。
• 定义节点和边含义的多种方法：
    • 基于**真实世界发生的事件**。
    • 使用**人类可理解的语言**（如英语）解释。
    • 使用一组**公理或规则**进行逻辑规范。
    • 通过一组**实例/示例**（如将“猫”的概念与多张猫的图像关联）。
    • 使用**嵌入**：基于文本语料库的统计计算得出。
• 关键点：不同方法服务于不同目的和上下文，但**没有一种方法能完全捕获含义**，所有方法合集也无法完全捕获。

【关键例子 / 实验 / Demo】
• 具体图示例：包含节点“Art”和“Bob”，以及一条从Art指向Bob的边，标签为“朋友”。用于说明如何为节点和边关联现实世界含义。
• WordNet示例：一个通过英语定义词语含义的语言学资源。

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 知识图谱的核心挑战和许多计算机科学领域（包括AI和数据库系统）的核心问题在于**如何以计算方式捕获含义**。
• ⚠️ 各种定义含义的方法都有其适用场景，但都不完备。

---

【时间戳】 09:46 – 14:02

【核心主题】知识图谱的悠久历史及其在现代应用中复兴的原因（以搜索引擎为例）。

【重点内容】
• 知识图谱在计算机科学中有悠久历史，尤其是在**知识表示**和**数据库系统**领域：
    • 知识表示：早期使用**语义网络**（本质是有向标签图），后演变为**描述逻辑**，并行发展出**概念图**。
    • 数据库系统：早期为**网状/图结构**，后演变为当今流行的**关系数据库系统**。
    • 与知识图谱最相关的工作是**三元组存储**的研究。
• 核心观点：以三元组形式存储信息的实践本身**并不新鲜**。
• 讲座旨在解释该领域为何出现**复兴**，将通过三个应用说明：**搜索引擎、数据集成、人工智能**。
• 搜索引擎中的知识图谱应用示例（Danny Vernicich的“冬季之旅”示例）：
    • 搜索“winter tour zurich”。
    • 结果页面不仅显示链接，还**直接展示从Wikipedia信息框提取的结构化事实**（如日期、地点）。
    • 这增强了搜索结果，是知识图谱应用的“冰山一角”。

【关键例子 / 实验 / Demo】
• “冬季之旅”搜索示例：展示了搜索引擎如何利用Wikipedia中的结构化数据（知识图谱）来增强搜索结果，直接呈现关键事实。

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 知识图谱的历史源远流长，当前复兴并非源于基础数据模型的新颖性。

【时间戳】 00:00 – 04:10

【核心主题】研讨会介绍、动机及课程结构概述。

【重点内容】
• 研讨会由 Naren 和 Mike 共同组织，主题为知识图谱。
• 组织动机：知识图谱被广泛应用于**网络搜索、问答、数据集成**，并成为**NLP、视觉及机器学习算法**首选的输出表示形式。
• 目标：传授知识图谱的**基本思想、概念、理论和应用**。
• 重要性：美国国家科学基金会（NSF）去年资助了约 **20个** 知识图谱项目。
• 课程结构（2021年春季）：
    • **周二**：课程核心内容，基于 **2020年系列30位受邀演讲者** 观点的**综合与总结**，形成课程笔记。
    • **周四**：邀请来自学术界和工业界的嘉宾进行演讲，通常为**两场30分钟的报告**，随后是问答环节。
    • 课程采用**两次18分钟**的会议形式（周二和周四），而非传统的单次两小时会议。
• 考核要求（斯坦福大学获得学分的学生）：
    • 完成所有 **10次** 周二课程的测验。
    • 提交 **10次** 周四课程中任意 **8次** 的书面总结。
• 这是一个**1个学分**的课程，要求较轻。

【关键例子 / 实验 / Demo】
• 无

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 周二课程内容主要是对去年系列讲座的综合，而非全新的嘉宾演讲。

---

【时间戳】 04:11 – 09:46

【核心主题】知识图谱的数学定义、构成要素及其含义的多种定义方式。

【重点内容】
• 知识图谱定义：一个**有向标签图**，其中**节点和边具有明确定义的含义**。
• 核心是数学上的有向标签图，重点在于**定义节点和边的含义**。
• 不同的数据模型对节点和边有不同称呼：
    • **主语-谓语-宾语**三元组。
    • **实体-关系-实体**三元组。
    • **类层次结构**：节点是类，边标为“子类”或“子集”关系。
• 含义定义示例：节点“Art”和“Bob”代表现实世界的人；边“朋友”可以定义为“Art在Facebook上向Bob发送了好友请求且Bob接受了该请求”。
• 对于抽象概念（如类），含义通常通过**文本描述**定义，更复杂的情况下可使用**逻辑语言**进行形式化规范。
• 定义节点和边含义的多种方法：
    • 基于**真实世界发生的事件**。
    • 使用**人类可理解的语言**（如英语）解释。
    • 使用一组**公理或规则**进行逻辑规范。
    • 通过一组**实例/示例**（如将“猫”的概念与多张猫的图像关联）。
    • 使用**嵌入**：基于文本语料库的统计计算得出。
• 关键点：不同方法服务于不同目的和上下文，但**没有一种方法能完全捕获含义**，所有方法合集也无法完全捕获。

【关键例子 / 实验 / Demo】
• 具体图示例：包含节点“Art”和“Bob”，以及一条从Art指向Bob的边，标签为“朋友”。用于说明如何为节点和边关联现实世界含义。
• WordNet示例：一个通过英语定义词语含义的语言学资源。

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 知识图谱的核心挑战和许多计算机科学领域（包括AI和数据库系统）的核心问题在于**如何以计算方式捕获含义**。
• ⚠️ 各种定义含义的方法都有其适用场景，但都不完备。

---

【时间戳】 09:46 – 14:02

【核心主题】知识图谱的悠久历史及其在现代应用中复兴的原因（以搜索引擎为例）。

【重点内容】
• 知识图谱在计算机科学中有悠久历史，尤其是在**知识表示**和**数据库系统**领域：
    • 知识表示：早期使用**语义网络**（本质是有向标签图），后演变为**描述逻辑**，并行发展出**概念图**。
    • 数据库系统：早期为**网状/图结构**，后演变为当今流行的**关系数据库系统**。
    • 与知识图谱最相关的工作是**三元组存储**的研究。
• 核心观点：以三元组形式存储信息的实践本身**并不新鲜**。
• 讲座旨在解释该领域为何出现**复兴**，将通过三个应用说明：**搜索引擎、数据集成、人工智能**。
• 搜索引擎中的知识图谱应用示例（Danny Vernicich的“冬季之旅”示例）：
    • 搜索“winter tour zurich”。
    • 结果页面不仅显示链接，还**直接展示从Wikipedia信息框提取的结构化事实**（如日期、地点）。
    • 这增强了搜索结果，是知识图谱应用的“冰山一角”。

【关键例子 / 实验 / Demo】
• “冬季之旅”搜索示例：展示了搜索引擎如何利用Wikipedia中的结构化数据（知识图谱）来增强搜索结果，直接呈现关键事实。

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 知识图谱的历史源远流长，当前复兴并非源于基础数据模型的新颖性。
【时间戳】 14:09 – 15:05

【核心主题】Wikipedia中Winterthur（温特图尔）和Ontario, California（加利福尼亚安大略）的twin towns（双胞胎城镇）和sister cities（姐妹城市）链接不对称问题。

【重点内容】
• Winterthur Wikipedia页面列出4个twin towns：2个在Switzerland（瑞士），1个在Czech Republic（捷克共和国），1个在Austria（奥地利）。
• Ontario, California Wikipedia页面列出sister cities，包括Winterthur，但Winterthur页面无反向链接。
• Twin towns和sister cities为相同概念（town twinning，城镇结谊），但链接不对称，无自动解析方法。
• 理想状态下链接应symmetric（对称）。

【关键例子 / 实验 / Demo】
• 示例：Winterthur页面无Ontario链接，但Ontario页面有Winterthur作为sister city，展示数据不一致。

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 链接不对称为big problem（大问题），影响数据完整性。

【时间戳】 15:05 – 16:28

【核心主题】Wikidata作为publicly curated knowledge graph（公开 curation 的知识图谱）解决链接不对称。

【重点内容】
• Wikidata为huge publicly curated knowledge graph（巨大公开 curation 知识图谱）。
• Winterthur Wikidata页面有relation：twinned administrative body（结谊行政体），链接到Ontario。
• Ontario Wikidata页面有相同relation，反向链接到Winterthur，实现systematic relationship（系统化关系）。

【关键例子 / 实验 / Demo】
• 示例：搜索Winterthur和Ontario Wikidata页面，展示互指的twinned administrative body。

【注意事项 / 易错点 / 老师特别强调的内容】
• 无

【时间戳】 16:28 – 17:52

【核心主题】Wikidata底层directed labeled graph（有向标签图）表示及其扩展链接。

【重点内容】
• 底层结构：directed labeled graph（有向标签图），节点为Winterthur和Ontario，边为twinned administrative body。
• 节点扩展链接：Winterthur part of Zurich metropolitan area（苏黎世都市区），in Switzerland；Ontario in United States，part of North America。
• 其他web sources（网络来源）使用Wikidata identifiers（标识符）发布数据，便于链接。
• 示例来源：Library of Congress（国会图书馆）发布Winterthur信息，使用Wikidata ID链接。
• 多个来源互链，形成growing movement（增长运动）。

【关键例子 / 实验 / Demo】
• 示例：Library of Congress数据链接Wikidata，实现信息整合。

【注意事项 / 易错点 / 老师特别强调的内容】
• 无

【时间戳】 17:52 – 19:26

【核心主题】结构化数据启用跨源查询，Schema.org提供共享词汇改善web搜索。

【重点内容】
• Structured data（结构化数据）支持queries（查询），如“display on a map the birth cities of people who died in Winterthur”（在地图上显示死于Winterthur的人的出生城市）。
• 查询需跨multiple data sources（多个数据来源），理解其schemas（模式）。
• Schema.org：effort to create shared vocabulary（创建共享词汇的努力），用于web数据发布，便于查询和结合信息。
• 知识图谱提升web search results（网络搜索结果）质量。
• Wikidata规模：无exact up-to-date data（确切最新数据），但巨大。

【关键例子 / 实验 / Demo】
• 查询示例：需整合多源数据，展示知识图谱潜力（目前不可行，但未来目标）。

【注意事项 / 易错点 / 老师特别强调的内容】
• ⚠️ 查询复杂性要求理解多源schemas。

【时间戳】 19:31 – 20:00【核心主题】Wikidata规模描述。【重点内容】
• Wikidata规模（约一年前数据）：over 80 million objects（超过8000万对象），over 1 billion relationships（超过10亿关系）。
• 链接到over 4800 public catalogs（超过4800个公共目录），包括Library of Congress（国会图书馆）。【关键例子 / 实验 / Demo】
• 无【注意事项 / 易错点 / 老师特别强调的内容】
• 无【时间戳】 20:00 – 22:37【核心主题】Wikidata知识图谱独特特征。【重点内容】
• Unprecedented scale（前所未有规模）：directed labeled graph representation（有向标签图表示），比以往更大。
• Community effort（社区努力）：curators（策展人）创建数据；外部组织如Library of Congress发布数据链接Wikidata。
• Data creation methods（数据创建方法）：hand-curated（手工 curation），automatically created（自动创建）via parsing Wikipedia（解析维基百科）、extraction tools（提取工具）、crowdsourcing（众包）。
• Explicit attention to meaning（对含义的明确关注）：Schema.org提供well-defined meanings（明确定义含义）以支持inference（推理）；一些relations可能无定义，但需agree and specify meanings（同意并指定含义）。
• Clear compelling use case（清晰引人注目的用例）：web search（网络搜索），服务billions of users and queries（数十亿用户和查询）；其他organizations使用Wikidata for multiple purposes（多用途）。【关键例子 / 实验 / Demo】
• 无【注意事项 / 易错点 / 老师特别强调的内容】
•  需characterize labels meanings（表征标签含义）以进行inference。【时间戳】 22:37 – 25:09【核心主题】知识图谱在数据整合中的用例：360度客户视图。【重点内容】
• 360 degree view of a customer（客户360度视图）：整合internal systems（内部系统）和external data（外部数据）以管理millions of customers（数百万客户）。
• Commercial data providers（商业数据提供商）：PitchBook curates funding info（ curation 融资信息，如VC funding startups, amounts）；FactSet curates supply chain networks（ curation 供应链网络，如vendor-supplier relations）。
• Applications（应用）：risk analysis（风险分析）for lending decisions（贷款决策），评估customers/suppliers status；business intelligence（商业智能）for targeted marketing（针对性营销）to recently funded startups。
• Data integration（数据整合）：combine sources（结合来源）into unified view（统一视图）；问题存在decades（数十年），核心挑战：translations across schemas（跨模式翻译），map elements（映射元素）or use shared schema（共享模式）。【关键例子 / 实验 / Demo】
• 示例：使用PitchBook和FactSet数据与internal info（内部信息）结合，评估supplier trouble（供应商问题）或target funded startups（针对融资初创企业）。【注意事项 / 易错点 / 老师特别强调的内容】
• 无【时间戳】 25:09 – 28:04【核心主题】知识图谱在数据整合中的优势：schema-free approach。【重点内容】
• Knowledge graphs popularity in data integration（知识图谱在数据整合中的流行）：offer schema-free approach（提供无模式方法）。
• Method（方法）：convert relational data（关系数据）from multiple sources to triples（三元组），store in graph database（图数据库），实现initial integration（初始整合）。
• Not true integration（非真正整合）：simple translation（简单翻译），未define mappings（定义映射）。
• Pay-as-you-go basis（按需付费基础）：delay hard work of mappings（延迟映射的辛苦工作）until needed for business question（业务问题）；then make connections（建立连接）for immediate value（即时价值）。
• Benefits（益处）：low barrier to entry（低进入门槛），quick start（快速启动）；easier visualization（更容易可视化），optimized for graph traversals（优化图遍历）。
• Later sessions（后续会话）：deeper into visualization and graph traversals support（深入可视化和图遍历支持）。【关键例子 / 实验 / Demo】
• 无【注意事项 / 易错点 / 老师特别强调的内容】
•  Knowledge graphs reduce barrier to entry in data integration。【时间戳】 28:04 – 30:06【核心主题】知识图谱在AI中的使用：作为输出表示和ML输入；NLP示例。【重点内容】
• Knowledge graphs in AI（知识图谱在AI中）：for output representation（输出表示）和input to machine learning（机器学习输入）。
• NLP example（NLP示例）：sentence "Albert Einstein was a German-born theoretical physicist who developed the theory of relativity"。
• Entity extraction（实体提取）：identify entities如Albert Einstein, theory of relativity；general: extract numbers, dates, time intervals；common: noun phrases（名词短语）。
• Relation extraction（关系提取）：relations如Albert Einstein born in Germany, occupation theoretical physicist, developed theory of relativity。
• Represent as knowledge graph（表示为知识图谱）。
• Inference（推理）：associate meanings with labels（将含义与标签关联）for question answering（问答）、common sense reasoning（常识推理）；derive conclusions如Albert Einstein was a physicist, developed new knowledge in physics。
• NLP debate（NLP争论）：some say no need to specify meanings，但need characterize labels（表征标签）to draw conclusions。【关键例子 / 实验 / Demo】
• 示例：从sentence提取entities和relations，构建graph，进行inference得出额外结论。【注意事项 / 易错点 / 老师特别强调的内容】
•  Must characterize relation meanings to enable inference。【时间戳】 30:06 – 30:52【核心主题】知识图谱在计算机视觉中的应用。【重点内容】
• Computer vision（计算机视觉）：given image，object detection（对象检测）identify objects。
• Relation extraction（关系提取）：relations between objects，如man wearing glasses, man feeding。【关键例子 / 实验 / Demo】
• 示例：图片中man wearing glasses, man feeding（某物），展示objects和relations。【注意事项 / 易错点 / 老师特别强调的内容】
• 无

【时间】 30:59–36:16
【主题】计算机视觉与知识的符号到数值转换

【核心知识点】
• 计算机视觉的目标：不止于识别图中物体和关系并以图（Graph）表示，更关键的是进行系统化的视觉推理（Systematic Visual Question Answering）和视觉问答（Visual Question Answering）。
• 推理前提：必须理解图中每个标签（Labels）的含义（Meanings），并明确基于这些标签可以进行或不可以进行哪些推断（Inferences）。
• 机器学习输入的普遍要求：当前大多数机器学习算法（如回归模型、神经网络）需要数值输入（Numerical Input）。
• 核心挑战：进行实体抽取（Entity Extraction）或关系抽取（Relation Extraction）时，需要将符号化的词语（Symbolic Words）转换为数字。
• 解决方案：词嵌入（Word Embeddings）和图嵌入（Graph Embeddings）是将符号表示（Symbolic Representations）转换为数值表示（Numerical Representations）的主流技术。
• 词嵌入的原始目标：提供计算词语相似度（Word Similarity）的工具（例如，计算“like”与“enjoy”的相似度）。
• 词嵌入的泛用性：现已被发现对多种语言理解任务（Language Understanding Tasks）普遍有效。
• 词嵌入的核心思想（Key Idea）：通过统计一个词语与其他词语相邻出现的频率（Counting how often it occurs next to other words）来捕捉其含义。
• 共现矩阵（Co-occurrence Matrix）：基于语料库（Corpus）计算词与词相邻的次数，形成共现计数矩阵（Matrix of Co-occurrence Counts）。
• 词义的向量表示：一个词的含义由其对应的共现计数矩阵的行向量（Row of Co-occurrence Counts）来捕获。
• 计算词语相似度：计算两个词对应向量之间的距离（Distance Between the Two Vectors）。
• 现实复杂度：真实语料库（Text Corpus）有数十亿词（Billions/Billion Plus Words），采用朴素方法（Naive Approach）会导致存储需求爆炸（Storage Requirement Will Blow Up）。
• 降维必要性（Dimensionality Reduction）：实践中必须进行降维。
• 典型词向量大小（Word Vector Representations Size）：通常在200维左右（In The Range Of 200）。
• 降维技术：来自线性代数（Linear Algebra）的奇异值分解（Singular Value Decomposition, SVD）等技术，或自动学习如何选择这200个数字的技术。
• 词嵌入的实际应用案例：搜索引擎的输入预测（Predicting What Are Likely Next Things You Might Type），其背后的语言模型（Language Model）由词嵌入驱动。

【重要例子 / 实验】
1.  **微型语料库示例**：
    *   **设置**：语料库仅包含三句话：“I like knowledge graphs.”，“I like databases.”，“I enjoy running.”。
    *   **过程**：计算词与词相邻的次数。例如，对于第一行（“I”）和第二列（“like”）的值为2，因为“like”在“I”后面出现了两次；对于第一行和“enjoy”列的值为1。
    *   **结果**：形成一个具体的共现计数矩阵。
    *   **结论**：词“I”的含义由其行向量[数值列表]表示；要计算“like”和“enjoy”的相似度，需计算它们对应行向量之间的距离。

【老师强调 / 警告 / 易错点】
⚠️ **视觉知识的核心是推理**：计算机视觉不只是识别和建图，更重要的是能够利用这个图进行系统化的推理和问答。
⚠️ **符号到数值转换是ML应用的必经步骤**：要将知识图（Knowledge Graph）或文本中的符号信息用于机器学习模型，必须经历词嵌入或图嵌入的转换过程。
⚠️ **朴素方法的存储不可行**：所展示的基于小型语料库的共现计数方法是直观的，但直接应用于大规模真实语料库是不可行的，因为存储需求会爆炸式增长。
⚠️ **降维是实践关键**：实际应用中必须使用SVD等技术将高维稀疏矩阵压缩到低维稠密向量（如200维）。

【其他细节 / 补充说明】
•   NLP领域有专门的课程深入探讨如何做好不同形式的词嵌入。
•   搜索引擎的输入预测功能是词嵌入在实践中的一个常见应用实例。

【时间】 36:22–40:22
【主题】图嵌入的原理、类比与应用

【核心知识点】
•   图嵌入的流行应用领域：推荐系统（Recommendation），例如电商网站（E-commerce Site）的商品推荐。
•   推荐系统的数据基础：用户历史购买数据（Historical Data On What Similar Customers Have Bought），这些数据以图（Graph）的形式存在。
•   推荐图的构建方式：节点（Node）是产品（Product），若两个产品倾向于被一起购买（Bought Together）或先后购买（Bought After Each Other），则在它们之间建立一条边（Edge）。
•   推荐问题的本质：一个符号结构（Symbolic Structure），但机器学习预测需要数值输入（Numerical Input）。
•   图嵌入在推荐中的目标：与NLP中的词嵌入目标类似，将离散的符号结构（Discrete Symbolic Structure）转换为向量（Vectors），以便计算节点相似度（Node Similarity）、节点间差异（Difference Between Nodes），并作为机器学习算法的输入。
•   **词嵌入到图嵌入的类比（Analogy）**：句子（Sentence）可以看作是一个线性图（Linear Graph），其中每个词是一个节点，每对相邻词之间有一条边。
•   基于类比的启发：词嵌入的计算可以视为在这个线性图上的图嵌入计算。
•   将任意图转换为线性路径的方法：随机游走图（Randomly Walk The Graph），每次随机游走都会产生一个线性路径（Linear Path）。
•   基于路径计算嵌入：在生成的线性路径上，可以统计哪些节点共同出现（Co-occur），从而像处理句子语料库一样构建共现计数矩阵。
•   节点嵌入（Node Embeddings）：为图中每个节点计算的向量表示。
•   计算节点相似度：基于节点嵌入向量可以轻松计算节点相似度（Node Similarity）或接近度（How Close They Are To Each Other）。
•   图嵌入（Graph Embedding）的通常指代：整个图的嵌入表示。
•   计算整个图嵌入的一种简单方法：将图中所有节点的嵌入向量求和（Sum of the Individual Node Embeddings）。
•   当前介绍的局限性：所呈现的是一个朴素且简化的图景（Naive and Simplistic Picture），旨在传达图嵌入与机器学习关联的基本直觉（Basic Intuition）。

【重要例子 / 实验】
1.  **推荐系统图示例**：
    *   **设置**：图中节点代表商品，边代表商品常被一起购买。
    *   **问题**：该图是符号结构，无法直接输入给需要数值的机器学习模型进行预测。
    *   **解决方案**：通过图嵌入技术（如随机游走生成路径，再计算共现）将其转换为节点向量。

【老师强调 / 警告 / 易错点】
⚠️ **词嵌入与图嵌入的目标相似性**：两者核心目标一致，都是将符号信息向量化以便用于机器学习。
⚠️ **随机游走是关键桥梁**：通过随机游走，可以将复杂的图结构转化为类似句子的线性序列，从而复用词嵌入的思想。
⚠️ **节点嵌入与图嵌入的区别**：“图嵌入”通常指整个图的向量表示，而“节点嵌入”是图中单个节点的向量表示。
⚠️ **当前讲解是直觉性的**：为了解释知识图与机器学习的关系，当前介绍是简化版本。图嵌入的有效计算和推理有专门的课程深入讲解。

【其他细节 / 补充说明】
•   存在专门的课程教授如何计算图嵌入并进行有效推理。
•   将节点嵌入求和以得到图嵌入是一种简单（Trivial Approach）的方法。

【时间】 40:29–47:08
【主题】知识图谱与AI的关系总结及领域新趋势

【核心知识点】
• 知识图谱（Knowledge Graphs）在AI中的双重角色：1) 作为自然语言处理（Natural Language Processing, NLP）和计算机视觉（Computer Vision）的输出表示（Output Representation）；2) 作为机器学习（Machine Learning）的输入（Input）。
• 嵌入方法（Embedding Approaches）的作用：使领域知识（Domain Knowledge）或背景知识（Background Knowledge）能够以知识图谱的形式输入到数值模型（Numerical Models）中，从而让机器学习做出更好的预测。
• 知识图谱的核心价值：在离散数学（Discrete Mathematics）的图（Graphs）这一基本构造之上，定义了**含义**（Meaning）。
• 关键问题（The Crux of The Problem）：以程序能够理解、并能以原则性方式（Principled Manner）处理含义的方式来定义含义。
• 推动近期知识图谱热潮（Recent Surge In Interest）的主要用例：网络搜索（Web Search），旨在改善拥有数十亿用户（Billions And Billions Of Users）的搜索结果。
• NLP与计算机视觉的进步：多年前人们还在为图像中识别物体（Identify Objects In An Image）而挣扎，无需构建知识图谱；但近年来，边缘检测（Edge Detection）、关系抽取（Relation Extraction）等技术的进步，产生了更好组织知识的需求。
• 机器学习进步的原因：算力提升（Compute Power Improvements）和数据可用性（Availability Of Data）。
• 知识图谱领域的新特点可总结为三点：规模（Scale）、自底向上的开发（Bottom-Up Development）、多种构建模式（Multiple Modes Of Construction）。

【重要例子 / 实验】
1.  **规模（Scale）的例证**：
    *   **设置/对比**：尽管有向标签图（Directed Label Graphs）已使用很久，但当前构建的规模是新的。
    *   **结果**：例如在Wikidata或许多NLP/视觉任务中构建的知识图谱，其规模达到了前所未有的水平（That Level Of Scale）。
    *   **结论**：这是知识图谱领域的新现象。
2.  **自底向上开发（Bottom-Up Development）的例证**：
    *   **传统方法（经典工作）**：由自上而下的设计（Top-Down Design）驱动，即构建新应用时，仔细思考领域模型（Domain Model），定义类和关系（Classes And Relations），再构建软件。
    *   **新方法（近期所见）**：由自底向上的方法驱动，基于可用数据（What Data Is Available）、发布的数据、市场可购买的数据、可提取（Extract）或实际学习（Learn）到的数据来开发知识图谱。
    *   **结论**：这种自底向上的创建方法是新的，但最终仍需围绕提取的信息设置含义边界（Put Some Boundaries Of Meaning Around），以便进行推理。
3.  **多种构建模式（Multiple Modes Of Construction）的例证**：
    *   **模式1：手动知识工程（Manual Knowledge Engineering）**：经典知识表示工作所驱动的主要方式，目前仍在大量进行（如手动输入）。
    *   **模式2：自动化抽取方法（Automated Extraction Methods）**：越来越多地使用NLP和视觉方法进行自动抽取。
    *   **模式3：众包方法（Crowdsourcing Approaches）**。
    *   **结果**：这些方法正共同用于创建大型知识图谱（Large Knowledge Graph Artifacts）。
    *   **限制条件/反例**：有人认为这完全是自动化的，但任何具有显著质量（Significant Quality）的知识图谱构建都必然包含一定的人工努力（Manual Effort），例如数据标注（Data Labeling）或数据验证（Data Validation）。
    *   **结论**：能够混合（Mix）这些方法来创建大型复杂知识图谱，是大约十年前（Until Say A Decade Ago）还无法实现的新能力。

【老师强调 / 警告 / 易错点】
⚠️ **含义是核心**：知识图谱超越普通图的关键在于定义了含义，这是整个问题的症结所在。
⚠️ **自底向上仍需含义边界**：即使以自底向上的方式收集信息，仍然必须能够对其进行推理，因此必须为其设定含义边界。
⚠️ **高质量图谱离不开人工**：宣称知识图谱构建完全自动化是不准确的。任何高质量的知识图谱构建都必然包含人工环节（如标注、验证）。
⚠️ **混合构建模式是新能力**：能够融合手动、自动和众包等多种模式来构建大型复杂知识图谱，是近十年才出现的新能力。

【其他细节 / 补充说明】
• 在知识表示（Knowledge Representation）、数据库（Databases）、NLP等多个计算机科学领域，关于知识图谱已有数十年的丰富研究历史（Rich History）。
• 下期课程预告：本周四由来自美国国家科学基金会（National Science Foundation）的Chaitanya Baru教授主讲，将概述该主题领域，并介绍一些他们目前正在资助的有趣项目（Interesting Projects）。
